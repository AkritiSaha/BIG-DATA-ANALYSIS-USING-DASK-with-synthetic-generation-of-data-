# BIG-DATA-ANALYSIS-USING-DASK-with-synthetic-generation-of-data-

**COMPANY** : CODTECH IT SOLUTIONS

**NAME**: AKRITI SAHA

**INTERN ID**: :CT04DM725

**DOMAIN**: DATA ANALYTICS

**DURATION**: 4 WEEEKS

**MENTOR**: NEELA SANTHOS KUMAR

**DESCRIPTION**: #Big Data Analysis Using Dask (with Synthetic Data)

Overview
This beginner-friendly project explores how to analyze large datasets using **Dask**, a Python library designed for parallel and distributed computing. Instead of using real data, synthetic data is generated to simulate large-scale scenarios, helping new learners understand big data techniques without relying on external datasets.

What I Did
- Generated **synthetic big data** using NumPy and pandas.
- Loaded data using **Dask DataFrames** to handle datasets larger than memory.
- Performed basic **data cleaning, filtering, and grouping** operations.
- Explored **lazy evaluation** and **parallelism** in Dask for faster computations.

 Why Dask?
Unlike pandas, Dask can:
- Scale to larger-than-memory datasets
- Run operations in parallel using all cores
- Integrate easily with familiar pandas syntax

Technologies Used
- Python
- Dask
- NumPy
- Pandas
- Jupyter Notebook

 What I Learned
- Basics of big data analysis
- How Dask improves performance over pandas
- How to work with large datasets using limited system memory


